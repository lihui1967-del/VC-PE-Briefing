import os
import re
import datetime
import requests
import feedparser

# ======================
#  æ•°æ®æºï¼ˆå…ˆç”¨ç¨³å®šæºï¼‰
# ======================

CHINA_FEEDS = [
    "https://rsshub.app/36kr/investment",
    "https://rsshub.app/36kr/newsflashes",
    "https://rsshub.app/cyzone/label/æŠ•èèµ„",
]

OVERSEAS_FEEDS = [
    "https://techcrunch.com/tag/funding/feed/",
]

# ======================
#  å¼ºè¿‡æ»¤è§„åˆ™ï¼ˆBç­–ç•¥ï¼‰
# ======================

ACTION_WORDS = ["å®Œæˆ", "è·", "è·å¾—", "å®£å¸ƒå®Œæˆ", "å®£å¸ƒè·å¾—"]
ROUND_WORDS = ["èèµ„", "å¤©ä½¿è½®", "Aè½®", "Bè½®", "Cè½®", "Dè½®", "Pre-A", "æˆ˜ç•¥èèµ„", "å¹¶è´­"]
NOISE_WORDS = ["è®ºå›", "å³°ä¼š", "æ´»åŠ¨", "ä¼šè®®", "æŠ¥å‘Š", "ç™½çš®ä¹¦", "è§‚ç‚¹", "ç›˜ç‚¹", "é¢„æµ‹"]

FUND_WORDS = ["å‹Ÿèµ„", "å‹Ÿé›†", "é¦–å…³", "ç»ˆå…³", "è®¾ç«‹", "åŸºé‡‘", "å¤‡æ¡ˆ"]

SECTOR_RULES = {
    "AI": ["AI", "äººå·¥æ™ºèƒ½", "å¤§æ¨¡å‹", "æœºå™¨äºº"],
    "åŒ»ç–—/ç”Ÿç‰©": ["åŒ»ç–—", "åŒ»è¯", "ç”Ÿç‰©", "åŸºå› "],
    "ç¡¬ç§‘æŠ€": ["èŠ¯ç‰‡", "åŠå¯¼ä½“", "ææ–™", "åˆ¶é€ "],
    "å‰æ²¿ç§‘æŠ€": ["é‡å­", "è„‘æœº", "æ ¸èšå˜"],
    "æ¶ˆè´¹": ["æ–°æ¶ˆè´¹", "å“ç‰Œ", "é›¶å”®", "é¤é¥®"],
}

AMOUNT_RE = re.compile(r"(\d+(?:\.\d+)?\s*(?:äº¿|ä¸‡)?\s*(?:äººæ°‘å¸|ç¾å…ƒ|ç¾é‡‘|å…ƒ)?)")

# ======================
#  å·¥å…·å‡½æ•°
# ======================

def clean(s):
    s = re.sub(r"<[^>]+>", "", s or "")
    return re.sub(r"\s+", " ", s).strip()

def has_any(text, keys):
    text = (text or "").lower()
    return any(k.lower() in text for k in keys)

def detect_sector(text):
    for sector, keys in SECTOR_RULES.items():
        if has_any(text, keys):
            return sector
    return "å…¶ä»–"

def extract_amount(text):
    m = AMOUNT_RE.search(text or "")
    return m.group(1) if m else "æœªæŠ«éœ²"

def parse_feed(url):
    items = []
    try:
        r = requests.get(url, timeout=20, headers={"User-Agent": "Mozilla/5.0"})
        r.raise_for_status()
        feed = feedparser.parse(r.content)
        for e in feed.entries[:40]:
            items.append({
                "title": clean(getattr(e, "title", "")),
                "link": getattr(e, "link", ""),
                "summary": clean(getattr(e, "summary", ""))[:200]
            })
    except Exception as ex:
        items.append({
            "title": f"RSSæŠ“å–å¤±è´¥ï¼š{url}",
            "link": url,
            "summary": str(ex)
        })
    return items

def is_true_deal(title):
    if has_any(title, NOISE_WORDS):
        return False
    return has_any(title, ACTION_WORDS) and has_any(title, ROUND_WORDS)

def is_true_fund(title):
    if has_any(title, NOISE_WORDS):
        return False
    return has_any(title, FUND_WORDS)

# ======================
#  ä¸»é€»è¾‘
# ======================

def main():

    today = (datetime.datetime.utcnow() + datetime.timedelta(hours=8)).strftime("%Y-%m-%d")

    try:

        deals = []
        funds = []

        for url in CHINA_FEEDS:
            items = parse_feed(url)

            for item in items:

                title = item["title"]
                blob = title + " " + item["summary"]

                if is_true_deal(title):
                    sector = detect_sector(blob)
                    if sector != "å…¶ä»–":
                        deals.append({
                            "title": title,
                            "link": item["link"],
                            "sector": sector,
                            "amount": extract_amount(blob)
                        })

                elif is_true_fund(title):
                    funds.append({
                        "title": title,
                        "link": item["link"],
                        "amount": extract_amount(blob)
                    })

        # å»é‡
        deals = list({d["title"]: d for d in deals}.values())[:15]
        funds = list({f["title"]: f for f in funds}.values())[:8]

        # ç»„è£… Markdown
        md = []
        md.append(f"# {today} VC/PE èèµ„æ™¨æŠ¥ï¼ˆBç­–ç•¥ï¼‰\n")

        md.append("## ğŸ‡¨ğŸ‡³ ä¸­å›½çœŸèèµ„\n")
        if deals:
            for i, d in enumerate(deals, 1):
                md.append(f"{i}. **[{d['title']}]({d['link']})**")
                md.append(f"   - èµ›é“ï¼š{d['sector']}ï½œé‡‘é¢ï¼š{d['amount']}")
        else:
            md.append("- ä»Šæ—¥æœªæŠ“åˆ°æ˜ç¡®å®Œæˆèèµ„æ ‡é¢˜\n")

        md.append("\n## ğŸ¦ åŸºé‡‘åŠ¨æ€\n")
        if funds:
            for i, f in enumerate(funds, 1):
                md.append(f"{i}. **[{f['title']}]({f['link']})**")
                md.append(f"   - è§„æ¨¡çº¿ç´¢ï¼š{f['amount']}")
        else:
            md.append("- ä»Šæ—¥æœªæŠ“åˆ°æ˜ç¡®å‹Ÿèµ„æ ‡é¢˜\n")

        md.append("\n## ğŸŒ æµ·å¤–å¯¹æ¯”\n")

        overseas = []
        for url in OVERSEAS_FEEDS:
            overseas.extend(parse_feed(url))

        for o in overseas[:5]:
            md.append(f"- **[{o['title']}]({o['link']})**")

        md_text = "\n".join(md)

        sendkey = os.environ["SENDKEY"]
        api = f"https://sctapi.ftqq.com/{sendkey}.send"

        requests.post(api, data={
            "title": f"{today} VC/PE æ™¨æŠ¥",
            "desp": md_text
        }, timeout=20)

    except Exception as ex:

        sendkey = os.environ["SENDKEY"]
        api = f"https://sctapi.ftqq.com/{sendkey}.send"

        requests.post(api, data={
            "title": f"{today} æ™¨æŠ¥ç”Ÿæˆå¤±è´¥",
            "desp": str(ex)
        }, timeout=20)


if __name__ == "__main__":
    main()
