import os
import re
import datetime
import requests
import feedparser

# ======================
# ç›´è¿ RSS/Atom æºï¼ˆä¸èµ° RSSHubï¼Œé¿å… 403ï¼‰
# ======================

CHINA_FEEDS = [
    # 36æ°ªï¼ˆå…¨ç«™ RSSï¼Œå†…å®¹è¾ƒæ³›ï¼Œä½†èƒ½ä½œä¸ºåº•æ± ï¼‰
    "https://36kr.com/feed",

    # åˆ›ä¸šé‚¦ï¼ˆå®˜æ–¹ RSSï¼šå†…å®¹ä¸å…¨ä½†å¯ç”¨ï¼‰
    "https://www.cyzone.cn/rss",

    # çŒäº‘ç½‘ï¼ˆæ›´æ¨èè¿™ä¸¤ä¸ªï¼šç¤¾åŒºé•¿æœŸä½¿ç”¨çš„ç›´è¿ RSSï¼‰
    "http://www.lieyunwang.com/feed",             # :contentReference[oaicite:1]{index=1}
    "http://www.lieyunwang.com/newrss/feed.xml",  # :contentReference[oaicite:2]{index=2}

    # é’›åª’ä½“ï¼ˆåäº§ä¸š/ç§‘æŠ€ï¼Œä¹Ÿä¼šå‡ºç°èèµ„æŠ¥é“ï¼‰
    "http://www.tmtpost.com/rss.xml",             # :contentReference[oaicite:3]{index=3}

    # åŠ¨ç‚¹ç§‘æŠ€ï¼ˆä¸­å›½ç§‘æŠ€/èèµ„ä¹Ÿæ¯”è¾ƒå¤šï¼‰
    "https://cn.technode.com/feed/",              # :contentReference[oaicite:4]{index=4}
]

OVERSEAS_FEEDS = [
    "https://techcrunch.com/tag/funding/feed/",
    "https://www.fiercebiotech.com/rss/xml",
]

# ======================
# Bç­–ç•¥ï¼šå®å¯å°‘ï¼Œä¹Ÿè¦â€œæ ‡é¢˜çº§çœŸèèµ„â€
# ======================

# æ ‡é¢˜å¿…é¡»å‘½ä¸­ï¼šèèµ„è¯ + è½®æ¬¡/é‡‘é¢/æŠ•èµ„æ–¹ä¿¡å·ï¼ˆè‡³å°‘å…¶ä¸€ï¼‰
DEAL_CORE = ["èèµ„", "è·èèµ„", "å®Œæˆèèµ„", "è¿½åŠ èèµ„", "æˆ˜ç•¥èèµ„"]
ROUND_WORDS = ["å¤©ä½¿è½®", "ç§å­è½®", "Pre-A", "PreA", "Aè½®", "A+è½®", "Bè½®", "Cè½®", "Dè½®", "Eè½®"]
INVESTOR_WORDS = ["é¢†æŠ•", "è·ŸæŠ•", "æŠ•èµ„", "åŠ æŒ"]
AMOUNT_WORDS = ["äº¿", "ä¸‡", "ç¾å…ƒ", "ç¾é‡‘", "äººæ°‘å¸", "RMB", "USD"]

# æ’é™¤å™ªéŸ³ï¼ˆå‡ºç°å°±ç›´æ¥å‰”é™¤ï¼‰
NOISE_WORDS = ["è®ºå›", "å³°ä¼š", "æ´»åŠ¨", "ä¼šè®®", "æŠ¥å‘Š", "ç™½çš®ä¹¦", "è§‚ç‚¹", "ç›˜ç‚¹", "é¢„æµ‹", "æ‹›è˜", "å‘å¸ƒä¼š", "å¼€å¹•", "é—­å¹•"]

# åŸºé‡‘åŠ¨æ€ï¼ˆæ ‡é¢˜çº§ï¼‰
FUND_WORDS = ["å‹Ÿèµ„", "å‹Ÿé›†", "é¦–å…³", "ç»ˆå…³", "è®¾ç«‹", "æˆç«‹", "å¤‡æ¡ˆ", "åŸºé‡‘", "GP", "LP"]

# ä½ å…³æ³¨çš„èµ›é“ï¼ˆç”¨äºåˆ†ç»„ + éèµ›é“å‰”é™¤ï¼‰
SECTOR_RULES = {
    "AI": ["AI", "äººå·¥æ™ºèƒ½", "å¤§æ¨¡å‹", "LLM", "AIGC", "å¤šæ¨¡æ€", "ç®—åŠ›", "æœºå™¨äºº", "å…·èº«", "è‡ªåŠ¨é©¾é©¶"],
    "åŒ»ç–—/ç”Ÿç‰©": ["åŒ»ç–—", "åŒ»è¯", "ç”Ÿç‰©", "å™¨æ¢°", "IVD", "åŸºå› ", "ç»†èƒ", "æŠ—ä½“", "è‚¿ç˜¤", "è¯Šæ–­", "åˆ¶è¯"],
    "ç¡¬ç§‘æŠ€": ["èŠ¯ç‰‡", "åŠå¯¼ä½“", "EDA", "ææ–™", "å…ˆè¿›åˆ¶é€ ", "å·¥ä¸š", "ä¼ æ„Ÿ", "å…‰ç”µ", "å‚¨èƒ½", "ç”µæ± ", "èˆªç©ºèˆªå¤©"],
    "å‰æ²¿ç§‘æŠ€": ["é‡å­", "è„‘æœº", "BCI", "æ ¸èšå˜", "ç©ºé—´", "å«æ˜Ÿ", "åˆæˆç”Ÿç‰©", "æ–°ææ–™", "è¶…å¯¼"],
    "æ¶ˆè´¹": ["æ–°æ¶ˆè´¹", "å“ç‰Œ", "é›¶å”®", "è¿é”", "é¤é¥®", "å’–å•¡", "ç¾å¦†", "æ¯å©´", "æ½®ç©", "å® ç‰©", "é¥®æ–™", "é£Ÿå“"],
}

AMOUNT_RE = re.compile(r"((?:è¶…|è¿‘|çº¦)?\s*\d+(?:\.\d+)?\s*(?:äº¿|ä¸‡)?\s*(?:äººæ°‘å¸|å…ƒ|ç¾å…ƒ|ç¾é‡‘|US\$|USD|RMB)?)", re.I)

def clean(s: str) -> str:
    s = re.sub(r"<[^>]+>", "", s or "")
    s = re.sub(r"\s+", " ", s).strip()
    return s

def has_any(text: str, keys) -> bool:
    t = (text or "").lower()
    return any(k.lower() in t for k in keys)

def detect_sector(text: str) -> str:
    for sector, keys in SECTOR_RULES.items():
        if has_any(text, keys):
            return sector
    return "å…¶ä»–"

def extract_amount(text: str) -> str:
    m = AMOUNT_RE.search((text or "").replace(",", ""))
    return m.group(1).strip() if m else "æœªæŠ«éœ²"

def parse_feed(url: str, limit=50):
    """
    è¿”å›: items(list), status(str)
    """
    try:
        r = requests.get(url, timeout=25, headers={"User-Agent": "Mozilla/5.0"})
        r.raise_for_status()
        feed = feedparser.parse(r.content)
        items = []
        for e in feed.entries[:limit]:
            items.append({
                "title": clean(getattr(e, "title", "")),
                "link": getattr(e, "link", ""),
                "summary": clean(getattr(e, "summary", ""))[:220],
            })
        return items, f"OK({len(items)})"
    except Exception as ex:
        return [], f"FAIL({type(ex).__name__}) {ex}"

def is_true_deal(title: str) -> bool:
    if not title:
        return False
    if has_any(title, NOISE_WORDS):
        return False

    # å¿…é¡»æœ‰â€œèèµ„â€æ ¸å¿ƒè¯
    if not has_any(title, DEAL_CORE) and "èèµ„" not in title:
        return False

    # å†è¦æ±‚è‡³å°‘å‘½ä¸­ï¼šè½®æ¬¡ / é‡‘é¢ä¿¡å· / æŠ•èµ„æ–¹ä¿¡å·ï¼ˆé˜²æ­¢â€œèèµ„è§‚ç‚¹/èèµ„è¯¾â€ï¼‰
    if has_any(title, ROUND_WORDS) or has_any(title, AMOUNT_WORDS) or has_any(title, INVESTOR_WORDS):
        return True

    return False

def is_fund_news(title: str) -> bool:
    if not title:
        return False
    if has_any(title, NOISE_WORDS):
        return False
    return has_any(title, FUND_WORDS)

def post_to_serverchan(title: str, desp_md: str):
    sendkey = os.environ["SENDKEY"]
    api = f"https://sctapi.ftqq.com/{sendkey}.send"
    r = requests.post(api, data={"title": title, "desp": desp_md}, timeout=20)
    r.raise_for_status()

def main():
    today = (datetime.datetime.utcnow() + datetime.timedelta(hours=8)).strftime("%Y-%m-%d")

    try:
        # 1) æŠ“å– + è¯Šæ–­
        diag = []
        all_items = []
        for url in CHINA_FEEDS:
            items, st = parse_feed(url)
            diag.append(f"- {url} -> {st}")
            for it in items:
                it["_src"] = url
            all_items.extend(items)

        # 2) è¿‡æ»¤çœŸèèµ„ + çœŸåŸºé‡‘
        deals, funds = [], []
        for it in all_items:
            title = it["title"]
            blob = f"{title} {it['summary']}"

            if is_true_deal(title):
                sector = detect_sector(blob)
                if sector != "å…¶ä»–":
                    deals.append({
                        "title": title,
                        "link": it["link"],
                        "sector": sector,
                        "amount": extract_amount(blob),
                        "src": it.get("_src", ""),
                    })
            elif is_fund_news(title):
                funds.append({
                    "title": title,
                    "link": it["link"],
                    "amount": extract_amount(blob),
                    "src": it.get("_src", ""),
                })

        # å»é‡ + æ§åˆ¶æ•°é‡ï¼ˆBç­–ç•¥ï¼šå®å¯å°‘ï¼‰
        deals = list({d["title"]: d for d in deals}.values())[:15]
        funds = list({f["title"]: f for f in funds}.values())[:10]

        # 3) æµ·å¤–å¯¹æ¯”ï¼ˆæ¢å¤ï¼‰
        overseas_pool = []
        odiag = []
        for url in OVERSEAS_FEEDS:
            items, st = parse_feed(url, limit=25)
            odiag.append(f"- {url} -> {st}")
            overseas_pool.extend(items)

        overseas = []
        for it in overseas_pool:
            blob = (it["title"] + " " + it["summary"]).lower()
            if any(k in blob for k in ["funding", "financing", "raised", "series", "seed", "round"]):
                overseas.append(it)
        overseas = list({o["title"]: o for o in overseas}.values())[:5]

        # 4) è¾“å‡º
        md = []
        md.append(f"# {today} VC/PE èèµ„æ™¨æŠ¥ï¼ˆBç­–ç•¥ï¼šå®å¯å°‘ä¹Ÿè¦çœŸï¼‰\n")

        md.append("## âœ… æŠ“å–è¯Šæ–­ï¼ˆä¸­å›½æºï¼‰")
        md.extend(diag)
        md.append("")

        md.append("## ğŸ‡¨ğŸ‡³ ä¸­å›½çœŸèèµ„ï¼ˆâ‰¤15ï¼‰")
        if deals:
            for i, d in enumerate(deals, 1):
                md.append(f"{i}. **[{d['title']}]({d['link']})**")
                md.append(f"   - èµ›é“ï¼š{d['sector']}ï½œé‡‘é¢ï¼š{d['amount']}")
        else:
            md.append("- ä»Šæ—¥æœªç­›åˆ°â€œæ ‡é¢˜çº§çœŸèèµ„â€æ¡ç›®ã€‚")
            md.append("- åŸå§‹æ ‡é¢˜æ ·æœ¬ï¼ˆå‰10æ¡ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦å†åŠ æº/å†è°ƒè§„åˆ™ï¼‰ï¼š")
            for i, it in enumerate(all_items[:10], 1):
                md.append(f"  {i}) {it['title']}")

        md.append("\n## ğŸ¦ åŸºé‡‘/å‹Ÿèµ„åŠ¨æ€ï¼ˆâ‰¤10ï¼‰")
        if funds:
            for i, f in enumerate(funds, 1):
                md.append(f"{i}. **[{f['title']}]({f['link']})**")
                md.append(f"   - è§„æ¨¡çº¿ç´¢ï¼š{f['amount']}")
        else:
            md.append("- ä»Šæ—¥æœªç­›åˆ°æ˜ç¡®å‹Ÿèµ„/è®¾ç«‹/å¤‡æ¡ˆç±»æ ‡é¢˜ã€‚")

        md.append("\n## ğŸŒ æµ·å¤–å¯¹æ¯”ï¼ˆâ‰¤5ï¼‰")
        md.append("### æŠ“å–è¯Šæ–­ï¼ˆæµ·å¤–æºï¼‰")
        md.extend(odiag)
        if overseas:
            md.append("")
            for o in overseas:
                md.append(f"- **[{o['title']}]({o['link']})**")
        else:
            md.append("- ä»Šæ—¥æœªæŠ“åˆ°æµ·å¤–èèµ„æ¡ç›®ï¼ˆå¯èƒ½æ˜¯æºå½“å¤©æ²¡æœ‰ funding æ–‡ç« ï¼Œæˆ–æŠ“å–å¤±è´¥ï¼‰ã€‚")

        post_to_serverchan(f"{today} VC/PE æ™¨æŠ¥", "\n".join(md))

    except Exception as ex:
        err_md = f"# {today} æ™¨æŠ¥ç”Ÿæˆå¤±è´¥ï¼ˆå·²æ•è·ï¼‰\n\n- é”™è¯¯ç±»å‹ï¼š{type(ex).__name__}\n- é”™è¯¯ä¿¡æ¯ï¼š{ex}\n\nè¯·åˆ° GitHub Actions æ—¥å¿—æŸ¥çœ‹è¯¦ç»†æŠ¥é”™ã€‚"
        post_to_serverchan(f"{today} æ™¨æŠ¥å¤±è´¥å‘Šè­¦", err_md)

if __name__ == "__main__":
    main()
